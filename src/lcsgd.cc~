#include <lcsgd.h>

#include <iostream>

namespace lcsgd {
LCSGD::LCSGD() : dataN_(0), updateN_(0), alpha_(1.0), lambda_(1.0) {}

LCSGD::~LCSGD() {}

void LCSGD::LoadData(const data_t& data) {
  data_ = data;
  Initialize();
}

void LCSGD::Initialize() {
  dataN_ = data_.size();
  std::vector<sparse_vector_t>(dataN_).swap(subgradients_);
}

int LCSGD::Update(int iterN) {
  for (int iter = 0; iter < iterN; ++iter) {
    UpdateOnce();
    ++updateN_;
  }

  return 0;
}

void LCSGD::UpdateOnce() {
  std::uniform_int_distribution<int> dist(0, dataN_);
  int index = dist(engine_);
  UpdateSubgradient(index);
  weight_ = (1.0 - alpha_ * lambda_) * weight_
      - alpha_ / dataN_ * average_subgradient_;
}

void LCSGD::UpdateSubgradient(int index) {
  const sparse_vector_t& sv = subgradients_[index];
  std::cout << "a:" << sv << std::endl;
  average_subgradient_ -= sv;
  subgradients_[index] = CalcSubgradient(index);
  average_subgradient_ += subgradients_[index];
}

sparse_vector_t LCSGD::CalcSubgradient(int index) {
  const datum_t& datum = data_[index];
  double loss = CalcLoss(datum);

  if (loss <= 0.0) return sparse_vector_t();

  const features_t& features = datum.features;
  sparse_vector_t sv(features.size());
  for (auto it = features.begin(); it != features.end(); ++it) {
    sv.coeffRef(it->first) = it->second;
  }
  return sv;
}

double LCSGD::CalcLoss(const datum_t& datum) {
  const features_t& features = datum.features;
  const binary_label_t& label = datum.label;

  double score = 0.0;
  for (auto it = features.begin(); it != features.end(); ++it) {
    score += weight_(it->first) * it->second;
  }

  // Hinge Loss case
  return 1.0 - score * label;
}

} //namespace lcsgd
